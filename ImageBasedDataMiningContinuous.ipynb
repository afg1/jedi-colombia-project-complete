{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageBasedDataMiningContinuous.ipynb\n",
    "‹ ImageBasedDataMining.ipynb › Copyright (C) ‹ 2019 › ‹ Andrew Green - andrew.green-2@manchester.ac.uk › This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "| date      | who     | note                                                  |\n",
    "|----------|----------|-------------------------------------------------------|\n",
    "| 20190201 |    afg   |  First version, adapted from MadagaSKA code           |\n",
    "| 20190208 |    afg   |  Updated code, completed up to point of plotting      |\n",
    "| 20190208 |    afg   |  Update paths in code to work with docker container   |\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to do image based data mining against a continuous outcome. The outcome could be whatever you like, provided it is a continuous variable; some examples include weight loss, muscle area loss and feeding tube duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SimpleITK'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-46a8021f23d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mhaveTQDM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msitk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'SimpleITK'"
     ]
    }
   ],
   "source": [
    "## Import libraries and set up\n",
    "\n",
    "import os\n",
    "import time\n",
    "import os.path\n",
    "import numpy as np\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    haveTQDM = True\n",
    "except:\n",
    "    haveTQDM = False\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we will use pandas to load the csv. The next cell contains all the pre-processing from the binary data mining, in a single cell. By the end of the cell, we should have a set of clean data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clinicalDataPath = \"/data/clinicalData.csv\"\n",
    "\n",
    "clinicalData = pd.read_csv(clinicalDataPath)\n",
    "\n",
    "ccrtOnlyPatients = clinicalData[(clinicalData[\"Oncologic Treatment Summary\"].str.contains('^CCRT', regex=True)) & (clinicalData[\"Oncologic Treatment Summary\"].str.contains('\\+', regex=True) == False)]\n",
    "len(ccrtOnlyPatients[\"Oncologic Treatment Summary\"])\n",
    "\n",
    "selectedPatients = ccrtOnlyPatients[ccrtOnlyPatients[\"Number of Fractions\"].astype(int) < 40]\n",
    "len(selectedPatients[\"Number of Fractions\"])\n",
    "\n",
    "def calculateBEDCorrection(df, early=True):\n",
    "    earlyAlphaBeta = 10.0\n",
    "    lateAlphaBeta  = 03.0\n",
    "    if early:\n",
    "        df = df.assign(BEDfactor = lambda d : 1.0 + d[\"Dose/Fraction (Gy/fx)\"].astype(float)/earlyAlphaBeta)\n",
    "    else:\n",
    "        df = df.assign(BEDfactor = lambda d : 1.0 + d[\"Dose/Fraction (Gy/fx)\"].astype(float)/lateAlphaBeta)\n",
    "    return df\n",
    "\n",
    "selectedPatients = calculateBEDCorrection(selectedPatients)\n",
    "\n",
    "selectedPatients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our BED correction, we can start loading data ready to do mining. We will load each image using SimpleITK, convert it to a numpy array and put it into a bit numpy array. We will concurrently load the binary status from the clinical data as well and put that into a numpy array.\n",
    "\n",
    "In the next cell, we will load all our data. Note that we pre-allocate the numpy array we will use to hold the data - this is a performance optimisation to make loading the data a bit quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dosesPath = \"/data/registeredDoses\"\n",
    "\n",
    "probeDose = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, \"{0:04d}.nii\".format(int(2)))))\n",
    "print(probeDose.shape)\n",
    "len(selectedPatients)\n",
    "\n",
    "doseArray = np.zeros((*probeDose.shape, len(selectedPatients)))\n",
    "statusArray = np.zeros((len(selectedPatients),1))\n",
    "\n",
    "print(doseArray.shape)\n",
    "\n",
    "\n",
    "n = 0\n",
    "for idx, pt in selectedPatients.iterrows():\n",
    "    doseArray[...,n] = pt.BEDfactor * sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, \"{0}.nii\".format(pt.ID.split(\"-\")[-1]))))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our data, and we have corrected all the doses tot eh same BED, we are ready to do continuous outcome image based data mining.\n",
    "\n",
    "For this we need to select a suitable outcome variable - I suggest weight loss as a good one to start with. \n",
    "\n",
    "The next cell defines a function that calculates the pearson correlation coefficient in each voxel of the dose distribution. To do this, we slightly modify the online calculation of variance used in the binary data mining to do online calculation of covariance. The formula for pearson's correlation coefficient is then:\n",
    "\n",
    "$ \\rho = \\frac{cov(X,Y)}{\\sigma_{x} \\sigma_{y}} $\n",
    "\n",
    "\n",
    "(note: strictly, this is for a population, but the estimates for variance and covariance we return are for a sample, so it will work)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagesCorrelation(doseData, continuousOutcome):\n",
    "    \"\"\"\n",
    "    Calculate a per-voxel correlation coefficient between two images. Uses Welford's method to calculate mean, variance and covariance. \n",
    "    \n",
    "    Inputs:\n",
    "        - doseData: the dose data, should be structured such that the number of patients in it is along the last axis\n",
    "        - statuses: the outcome labels. 1 indicates an event, 0 indicates no event\n",
    "    Returns:\n",
    "        - rhoValues: an array of the same size as one of the images which contains the per-voxel rho values\n",
    "    \"\"\"\n",
    "    doseMean = np.zeros_like(doseData[...,0])\n",
    "    doseStd = np.zeros_like(doseData[...,0])\n",
    "    C = np.zeros_like(doseData[...,0])\n",
    "    \n",
    "    outcomeMean = 0.0\n",
    "    outcomeVar = 0.0\n",
    "    doseMean = doseData[...,0]\n",
    "    outcomeMean = continuousOutcome[0]\n",
    "    subjectCount = 1.0\n",
    "    \n",
    "    print(doseData[...,1:].shape, doseMean.shape)\n",
    "    for n,y in zip(range(1, doseData.shape[-1]), continuousOutcome[1:]):\n",
    "        x = doseData[...,n]\n",
    "        subjectCount += 1.0\n",
    "        dx = x - doseMean\n",
    "        \n",
    "        om = doseMean.copy()\n",
    "        yom = outcomeMean.copy()\n",
    "\n",
    "        doseMean += dx/subjectCount\n",
    "        outcomeMean += (y - outcomeMean)/subjectCount\n",
    "\n",
    "        doseStd += ((x - om)*(x - doseMean))\n",
    "        outcomeVar += (y - yom)*(y - outcomeMean)\n",
    "\n",
    "        C += (dx * (y - outcomeMean))\n",
    "        \n",
    "    doseStd /= (subjectCount)\n",
    "    outcomeVar /= (subjectCount)\n",
    "    covariance = C / (subjectCount - 1) ## Bessel's correction for a sample\n",
    "\n",
    "    rho = covariance / (np.sqrt(doseStd) * np.sqrt(outcomeVar))\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is very similar to the one we used in the binary IBDM code, but this time it also calculates the covariance between dose in each voxel and the continuous outcome variable. We then use that covariance to calculate the correlation between dose and outcome.\n",
    "\n",
    "Now we can apply the mining to some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dosesPath = \"/data/registeredDoses\"\n",
    "\n",
    "\n",
    "probeDose = sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, \"{0:04d}.nii\".format(int(2)))))\n",
    "print(probeDose.shape)\n",
    "len(selectedPatients)\n",
    "\n",
    "doseArray = np.zeros((*probeDose.shape, len(selectedPatients)))\n",
    "weightLoss = np.zeros((len(selectedPatients),1))\n",
    "print(doseArray.shape)\n",
    "n = 0\n",
    "for idx, pt in selectedPatients.iterrows():\n",
    "    doseArray[...,n] = pt.BEDfactor * sitk.GetArrayFromImage(sitk.ReadImage(os.path.join(dosesPath, \"{0}.nii\".format(pt.ID.split(\"-\")[-1]))))\n",
    "    weightLoss[n] = pt.WeightStop - pt.WeightStart\n",
    "    n += 1\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlationmap = imagesCorrelation(doseArray, weightLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got our correlation map with the true correspondence of weight loss to dose, we can compute the permutation distribution again to get the significance of the correlation.\n",
    "\n",
    "This works just like before, we just rearrange the weight loss values and re-calculate the correlation coefficient and look at how the most extreme voxels behave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPermutation(doseData, outcome):\n",
    "    \"\"\"\n",
    "    Permute the statuses and return the maximum t value for this permutation\n",
    "    Inputs:\n",
    "        - doseData: the dose data, should be structured such that the number of patients in it is along the last axis\n",
    "        - outcome: the outcome values. Shuold be a continuous number. These will be permuted in this function to \n",
    "                    assess the null hypothesis of no dose interaction\n",
    "    Returns:\n",
    "        - (tMin, tMax): the extreme values of the whole t-value map for this permutation\n",
    "    \"\"\"\n",
    "    poutcome = np.random.permutation(outcome)\n",
    "    permT = imagesCorrelation(doseData, poutcome)\n",
    "    return (np.min(permT), np.max(permT))\n",
    "\n",
    "\n",
    "def permutationTest(doseData, outcome, nperm=1000):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to get the global p-value and t-thresholds\n",
    "    Inputs:\n",
    "        - doseData: the dose data, should be structured such that the number of patients in it is along the last axis\n",
    "        - outcome: the outcome labels. Should be a continuous number.\n",
    "        - nperm: The number of permutations to calculate. Defaults to 1000 which is the minimum for reasonable accuracy\n",
    "    Returns:\n",
    "        - globalPNeg: the global significance of the test for negative t-values\n",
    "        - globalPPos: the global significance of the test for positive t-values\n",
    "        - tThreshNeg: the list of minT from all the permutations, use it to set a significance threshold.\n",
    "        - tThreshPos: the list of maxT from all the permutations, use it to set a significance threshold.\n",
    "    \"\"\"\n",
    "    tthresh = []\n",
    "    gtCount = 0\n",
    "    ltCount = 0\n",
    "    trueT = imagesCorrelation(doseData, outcome)\n",
    "    trueMaxT = np.max(trueT)\n",
    "    trueMinT = np.min(trueT)\n",
    "    if haveTQDM:\n",
    "        for perm in tqdm(range(nperm)):\n",
    "            tthresh.append(doPermutation(doseData, outcome))\n",
    "            if tthresh[-1][1] > trueMaxT:\n",
    "                gtCount += 1.0\n",
    "            if tthresh[-1][0] < trueMinT:\n",
    "                ltCount += 1.0\n",
    "    else:\n",
    "        for perm in range(nperm):\n",
    "            tthresh.append(doPermutation(doseData, outcome))\n",
    "            if tthresh[-1][1] > trueMaxT:\n",
    "                gtCount += 1.0\n",
    "            if tthresh[-1][0] < trueMinT:\n",
    "                ltCount += 1.0\n",
    "    \n",
    "    globalpPos = gtCount / float(nperm)\n",
    "    globalpNeg = ltCount / float(nperm)\n",
    "    tthresh = np.array(tthresh)\n",
    "    return (globalpNeg, globalpPos, sorted(tthresh[:,0]), sorted(tthresh[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this function with our data, we will get back the global significance and threshold values of $\\rho$. We can then use a contour plot at the 95th percentile to indicate regions of significance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
